{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6DxJSAjNpWj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4Z8Cjr3-CJk"
   },
   "outputs": [],
   "source": [
    "# train = np.load('physionet_2012_train.csv')\n",
    "# test = np.load('physionet_2012_test.csv')\n",
    "save_path = ''  # Set your path for sang files\n",
    "read_path = ''\n",
    "df = pd.read_csv(read_path + 'physionet_2012_train.csv', engine = 'python')\n",
    "df_2 = pd.read_csv(read_path + 'physionet_2012_test.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yRXY_jGMH1Su",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>ICUType</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574619</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574620</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>44.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574621</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>44.916668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574622</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>45.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574623</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>46.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574624 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pid  timestamp  Weight   ALP   ALT   AST  Albumin   BUN  \\\n",
       "0       PS00000000   0.000000    65.0   NaN   NaN   NaN      NaN   NaN   \n",
       "1       PS00000000   1.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "2       PS00000000   2.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "3       PS00000000   3.350000     NaN  82.0  12.0  17.0      3.8   NaN   \n",
       "4       PS00000000   3.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "...            ...        ...     ...   ...   ...   ...      ...   ...   \n",
       "574619  PS00007670  43.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574620  PS00007670  44.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574621  PS00007670  44.916668     NaN   NaN   NaN   NaN      NaN  28.0   \n",
       "574622  PS00007670  45.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574623  PS00007670  46.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "\n",
       "        Bilirubin  Cholesterol  ...  TroponinI  TroponinT  Urine   WBC  pH  \\\n",
       "0             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "1             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "2             NaN          NaN  ...        NaN        NaN  350.0   NaN NaN   \n",
       "3             0.5        191.0  ...        NaN        NaN    NaN   NaN NaN   \n",
       "4             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "...           ...          ...  ...        ...        ...    ...   ...  ..   \n",
       "574619        NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "574620        NaN          NaN  ...        NaN        NaN  180.0   NaN NaN   \n",
       "574621        NaN          NaN  ...        NaN        NaN    NaN  14.1 NaN   \n",
       "574622        NaN          NaN  ...        NaN        NaN  110.0   NaN NaN   \n",
       "574623        NaN          NaN  ...        NaN        NaN   50.0   NaN NaN   \n",
       "\n",
       "        Age  Gender  Height  ICUType  target  \n",
       "0        41       0     NaN        4       0  \n",
       "1        41       0     NaN        4       0  \n",
       "2        41       0     NaN        4       0  \n",
       "3        41       0     NaN        4       0  \n",
       "4        41       0     NaN        4       0  \n",
       "...     ...     ...     ...      ...     ...  \n",
       "574619   55       0     NaN        3       0  \n",
       "574620   55       0     NaN        3       0  \n",
       "574621   55       0     NaN        3       0  \n",
       "574622   55       0     NaN        3       0  \n",
       "574623   55       0     NaN        3       0  \n",
       "\n",
       "[574624 rows x 44 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NnpKgkcnJanB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['timestamp'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MotUsx-vKbHr"
   },
   "source": [
    "### Sort the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yoCUs3LTKHMw"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['pid', 'timestamp'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mu6lONY9Kj3q"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>ICUType</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>1.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS00000000</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574619</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>43.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574620</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>44.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574621</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>44.916668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574622</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>45.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574623</th>\n",
       "      <td>PS00007670</td>\n",
       "      <td>46.666668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574624 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pid  timestamp  Weight   ALP   ALT   AST  Albumin   BUN  \\\n",
       "0       PS00000000   0.000000    65.0   NaN   NaN   NaN      NaN   NaN   \n",
       "1       PS00000000   1.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "2       PS00000000   2.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "3       PS00000000   3.350000     NaN  82.0  12.0  17.0      3.8   NaN   \n",
       "4       PS00000000   3.783333     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "...            ...        ...     ...   ...   ...   ...      ...   ...   \n",
       "574619  PS00007670  43.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574620  PS00007670  44.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574621  PS00007670  44.916668     NaN   NaN   NaN   NaN      NaN  28.0   \n",
       "574622  PS00007670  45.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "574623  PS00007670  46.666668     NaN   NaN   NaN   NaN      NaN   NaN   \n",
       "\n",
       "        Bilirubin  Cholesterol  ...  TroponinI  TroponinT  Urine   WBC  pH  \\\n",
       "0             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "1             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "2             NaN          NaN  ...        NaN        NaN  350.0   NaN NaN   \n",
       "3             0.5        191.0  ...        NaN        NaN    NaN   NaN NaN   \n",
       "4             NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "...           ...          ...  ...        ...        ...    ...   ...  ..   \n",
       "574619        NaN          NaN  ...        NaN        NaN    NaN   NaN NaN   \n",
       "574620        NaN          NaN  ...        NaN        NaN  180.0   NaN NaN   \n",
       "574621        NaN          NaN  ...        NaN        NaN    NaN  14.1 NaN   \n",
       "574622        NaN          NaN  ...        NaN        NaN  110.0   NaN NaN   \n",
       "574623        NaN          NaN  ...        NaN        NaN   50.0   NaN NaN   \n",
       "\n",
       "        Age  Gender  Height  ICUType  target  \n",
       "0        41       0     NaN        4       0  \n",
       "1        41       0     NaN        4       0  \n",
       "2        41       0     NaN        4       0  \n",
       "3        41       0     NaN        4       0  \n",
       "4        41       0     NaN        4       0  \n",
       "...     ...     ...     ...      ...     ...  \n",
       "574619   55       0     NaN        3       0  \n",
       "574620   55       0     NaN        3       0  \n",
       "574621   55       0     NaN        3       0  \n",
       "574622   55       0     NaN        3       0  \n",
       "574623   55       0     NaN        3       0  \n",
       "\n",
       "[574624 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrVvK3U4htIu"
   },
   "source": [
    "### Organize data: patient by patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EcCgj_3mJghF"
   },
   "outputs": [],
   "source": [
    "###############  Organize data: patient by patient (time series): without patient ID ###############\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pserial = df.pid[0]\n",
    "dfindex = 0\n",
    "dataindex = 0\n",
    "data = [[]]\n",
    "tp_num = len(df.pid)\n",
    "dfvalues = df.values\n",
    "dfvalues = dfvalues.tolist()\n",
    "\n",
    "for i in range(tp_num):\n",
    "    #print(\"Organizing %d / %d patients\"% (dfindex + 1, len(dfvalues)))\n",
    "    if df.pid[dfindex] == pserial:\n",
    "        #data[dataindex].append(dfvalues[dfindex][1:]) # if we don't need the serial number of patient\n",
    "        data[dataindex].append(dfvalues[dfindex][0:])\n",
    "    else :\n",
    "        pserial = df.pid[dfindex]\n",
    "        data.append([])\n",
    "        dataindex += 1\n",
    "        #data[dataindex].append(dfvalues[dfindex][1:]) # if we don't need the serial number of patient\n",
    "        data[dataindex].append(dfvalues[dfindex][0:])\n",
    "\n",
    "    dfindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XvZiJk9zLppQ"
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.sort_values(by=['pid', 'timestamp'])\n",
    "df_2 = df_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HReXHPDqLzN4"
   },
   "outputs": [],
   "source": [
    "###############  Organize data: patient by patient (time series): without patient ID ###############\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pserial = df_2.pid[0]\n",
    "dfindex = 0\n",
    "dataindex = 0\n",
    "data_2 = [[]]\n",
    "tp_num = len(df_2.pid)\n",
    "dfvalues = df_2.values\n",
    "dfvalues = dfvalues.tolist()\n",
    "\n",
    "for i in range(tp_num):\n",
    "    #print(\"Organizing %d / %d patients\"% (dfindex + 1, len(dfvalues)))\n",
    "    if df_2.pid[dfindex] == pserial:\n",
    "        #data[dataindex].append(dfvalues[dfindex][1:]) # if we don't need the serial number of patient\n",
    "        data_2[dataindex].append(dfvalues[dfindex][0:])\n",
    "    else :\n",
    "        pserial = df_2.pid[dfindex]\n",
    "        data_2.append([])\n",
    "        dataindex += 1\n",
    "        #data[dataindex].append(dfvalues[dfindex][1:]) # if we don't need the serial number of patient\n",
    "        data_2[dataindex].append(dfvalues[dfindex][0:])\n",
    "\n",
    "    dfindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-J_L0Gi3WVpY"
   },
   "outputs": [],
   "source": [
    "data2 = []\n",
    "patient_index = 0\n",
    "\n",
    "for patient in data:\n",
    "    #print('Constructing %d/%d input sequences' % (patient_index + 1, len(data)))\n",
    "\n",
    "    data_tmp = []\n",
    "    avl_flag = 0\n",
    "\n",
    "    # search for the first cirrhosis date (if exist)\n",
    "    for tp in patient:\n",
    "        if tp[43] == 1: # [43] now is the target status\n",
    "            base = tp[1]\n",
    "            # print(base)\n",
    "            avl_flag = 1\n",
    "            break\n",
    "\n",
    "    if avl_flag == 1 or avl_flag == 0:\n",
    "        for tp in patient:\n",
    "          if tp[1] >= 0 and tp[1] <= 12: # find tps before the index time 24hr\n",
    "              tmp = tp\n",
    "              #print(tmp[1])\n",
    "              data_tmp.append(tmp[1:])\n",
    "        data2.append(data_tmp)\n",
    "\n",
    "    else: pass\n",
    "\n",
    "\n",
    "    patient_index += 1\n",
    "\n",
    "data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_EOcecV-bpck"
   },
   "outputs": [],
   "source": [
    "data2_2 = []\n",
    "patient_index = 0\n",
    "\n",
    "for patient in data_2:\n",
    "    #print('Constructing %d/%d input sequences' % (patient_index + 1, len(data_2)))\n",
    "\n",
    "    data_tmp = []\n",
    "    avl_flag = 0\n",
    "\n",
    "    # search for the first cirrhosis date (if exist)\n",
    "    for tp in patient:\n",
    "        if tp[43] == 1: # [43] now is the target status\n",
    "            base = tp[1]\n",
    "            # print(base)\n",
    "            avl_flag = 1\n",
    "            break\n",
    "\n",
    "    if avl_flag == 1 or avl_flag == 0:\n",
    "        for tp in patient:\n",
    "          if tp[1] >= 0 and tp[1] <= 12: # find tps before the index time 24hr\n",
    "              tmp = tp\n",
    "              #print(tmp[1])\n",
    "              data_tmp.append(tmp[1:])\n",
    "        data2_2.append(data_tmp)\n",
    "\n",
    "    else: pass\n",
    "\n",
    "\n",
    "    patient_index += 1\n",
    "\n",
    "data_2 = data2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21_hnhmLhpH6"
   },
   "source": [
    "### mean mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lZsZVGrTdtyU"
   },
   "outputs": [],
   "source": [
    "# calculate input feature mean of training set for imputation\n",
    "\n",
    "cat_ft_num = 3\n",
    "imputation = []\n",
    "\n",
    "for findex in range(len(data[0][0])):   # len(data[0][0]) is the number of input features\n",
    "    count = 0\n",
    "    total = 0\n",
    "\n",
    "    if findex >= (len(data[0][0]) - cat_ft_num): # the last 3 features are categorical, so we use most frequent value instead of mean for imputation\n",
    "        temp1 = []\n",
    "        for patient in data:\n",
    "            for tp in patient:\n",
    "                if np.isnan(tp[findex]) == False:\n",
    "                    temp1.append(tp[findex])\n",
    "        try:\n",
    "            imputation.append(np.bincount(temp1).argmax())\n",
    "        except:\n",
    "            imputation.append(-1) # means no feasible imputation for this feature. You can cange \"-1\" to other special signals\n",
    "\n",
    "    else:  # for non-categorical features, calculate the feature mean\n",
    "        for patient in data:\n",
    "            for tp in patient:\n",
    "                if np.isnan(tp[findex]) == False:\n",
    "                    total += tp[findex]\n",
    "                    count += 1\n",
    "        try:\n",
    "            imputation.append(total/count)\n",
    "        except:\n",
    "            imputation.append(-1) # means no feasible imputation for this feature. You can cange \"-1\" to other special signals\n",
    "\n",
    "# impute the training, validation, and testing set\n",
    "pindex = 0\n",
    "size = len(data)\n",
    "for patient in data:\n",
    "    #print('Imputing the training set : %d/%d'%(pindex + 1, size))\n",
    "    tpindex = 0\n",
    "    for tp in patient:\n",
    "        for findex in range(len(data[0][0])):\n",
    "            if np.isnan(data[pindex][tpindex][findex]) == True:\n",
    "                data[pindex][tpindex][findex] = imputation[findex]\n",
    "        tpindex += 1\n",
    "    pindex += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Qm0WlinUeV55"
   },
   "outputs": [],
   "source": [
    "# calculate input feature mean of training set for imputation\n",
    "\n",
    "cat_ft_num = 3\n",
    "imputation = []\n",
    "\n",
    "for findex in range(len(data_2[0][0])):   # len(data[0][0]) is the number of input features\n",
    "    count = 0\n",
    "    total = 0\n",
    "\n",
    "    if findex >= (len(data_2[0][0]) - cat_ft_num): # the last 3 features are categorical, so we use most frequent value instead of mean for imputation\n",
    "        temp1 = []\n",
    "        for patient in data_2:\n",
    "            for tp in patient:\n",
    "                if np.isnan(tp[findex]) == False:\n",
    "                    temp1.append(tp[findex])\n",
    "        try:\n",
    "            imputation.append(np.bincount(temp1).argmax())\n",
    "        except:\n",
    "            imputation.append(-1) # means no feasible imputation for this feature. You can cange \"-1\" to other special signals\n",
    "\n",
    "    else:  # for non-categorical features, calculate the feature mean\n",
    "        for patient in data_2:\n",
    "            for tp in patient:\n",
    "                if np.isnan(tp[findex]) == False:\n",
    "                    total += tp[findex]\n",
    "                    count += 1\n",
    "        try:\n",
    "            imputation.append(total/count)\n",
    "        except:\n",
    "            imputation.append(-1) # means no feasible imputation for this feature. You can cange \"-1\" to other special signals\n",
    "\n",
    "# impute the training, validation, and testing set\n",
    "pindex = 0\n",
    "size = len(data_2)\n",
    "for patient in data_2:\n",
    "    #print('Imputing the training set : %d/%d'%(pindex + 1, size))\n",
    "    tpindex = 0\n",
    "    for tp in patient:\n",
    "        for findex in range(len(data_2[0][0])):\n",
    "            if np.isnan(data_2[pindex][tpindex][findex]) == True:\n",
    "                data_2[pindex][tpindex][findex] = imputation[findex]\n",
    "        tpindex += 1\n",
    "    pindex += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.14.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9MVWcX0igZb"
   },
   "source": [
    "### zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FhcCPrTRijka"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "padded_data = tf.keras.preprocessing.sequence.pad_sequences(data, maxlen=12, dtype='float32')\n",
    "padded_data_2 = tf.keras.preprocessing.sequence.pad_sequences(data_2, maxlen=12, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ANMMOl7Uis4w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 12, 43)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(padded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pasftd32jzsx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 12, 43)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(padded_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5oUpclhlM0f"
   },
   "source": [
    "### show the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5pvSwC7clIWh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = padded_data[:, :, 42].astype(int)\n",
    "flattened_labels = labels.flatten()\n",
    "label_counts = np.bincount(flattened_labels)\n",
    "plt.bar([0, 1], label_counts, color=['blue', 'orange'])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NsJtiY5cmT6y"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_2 = padded_data_2[:, :, 42].astype(int)\n",
    "flattened_labels = labels_2.flatten()\n",
    "label_counts = np.bincount(flattened_labels)\n",
    "plt.bar([0, 1], label_counts, color=['blue', 'orange'])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imBbKWvbnQNE"
   },
   "source": [
    "### delete label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ixqXymoCnS59"
   },
   "outputs": [],
   "source": [
    "data_without_labels = np.delete(padded_data, 42, axis=2)\n",
    "data_without_labels_2 = np.delete(padded_data_2, 42, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OyTzLsMtqCRC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7671, 12, 42)\n",
      "(2400, 12, 42)\n",
      "(7671, 12)\n",
      "(2400, 12)\n"
     ]
    }
   ],
   "source": [
    "print(data_without_labels.shape)\n",
    "print(data_without_labels_2.shape)\n",
    "print(labels.shape)\n",
    "print(labels_2.shape)\n",
    "labels = tf.expand_dims(labels, axis=2)\n",
    "labels_2 = tf.expand_dims(labels_2, axis=2)\n",
    "# print(labels.shape)\n",
    "# print(labels_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kJV34ySn4BC"
   },
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7jLaaVzxn7wu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SWBLSq4an9gn"
   },
   "outputs": [],
   "source": [
    "x_train = data_without_labels\n",
    "y_train = labels\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA0rl4__q3yl"
   },
   "source": [
    "### model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 42)]             0         []                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 12, 128)              5504      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 12, 128)              8368      ['dense_4[0][0]',             \n",
      " ltiHeadAttention)                                                   'dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 12, 128)              0         ['dense_4[0][0]',             \n",
      " OpLambda)                                                           'multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 12, 128)              256       ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 12, 4)                516       ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 12, 128)              640       ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 12, 128)              0         ['layer_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'dense_6[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 12, 128)              256       ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 12, 128)              0         ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 12, 1)                129       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15669 (61.21 KB)\n",
      "Trainable params: 15669 (61.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LayerNormalization, MultiHeadAttention, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def transformer_encoder(inputs, num_heads, ff_dim, dropout=0.15):\n",
    "    # Attention and Normalization\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(inputs, inputs)\n",
    "    proj_input = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
    "    # Feed Forward\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(proj_input)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    # Output and Normalization\n",
    "    encoder_output = LayerNormalization(epsilon=1e-6)(proj_input + ff_output)\n",
    "    return Dropout(dropout)(encoder_output)\n",
    "\n",
    "# Input\n",
    "input_layer = Input(shape=(12, 42))\n",
    "\n",
    "# Embedding\n",
    "x = Dense(128, activation=\"relu\")(input_layer)\n",
    "\n",
    "# Adding Positional Encoding (implement or use a predefined function)\n",
    "\n",
    "# Transformer Blocks\n",
    "x = transformer_encoder(x, num_heads=4, ff_dim=4)\n",
    "# Add more transformer_encoder layers as needed\n",
    "\n",
    "# Output\n",
    "output = Dense(1)(x)  # Adjust the activation function and dimensions as per your task\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Adjust optimizer and loss function as needed\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 2s 8ms/step - loss: 0.3320 - val_loss: 0.1429\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1650 - val_loss: 0.1252\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1359 - val_loss: 0.1271\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1263 - val_loss: 0.1269\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1223 - val_loss: 0.1265\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1209 - val_loss: 0.1358\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1203 - val_loss: 0.1239\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1197 - val_loss: 0.1316\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1194 - val_loss: 0.1233\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1174 - val_loss: 0.1241\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1166 - val_loss: 0.1258\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1161 - val_loss: 0.1234\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1157 - val_loss: 0.1254\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1150 - val_loss: 0.1218\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1168 - val_loss: 0.1233\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1158 - val_loss: 0.1276\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1154 - val_loss: 0.1221\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1161 - val_loss: 0.1237\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1156 - val_loss: 0.1307\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1157 - val_loss: 0.1314\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1146 - val_loss: 0.1245\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1140 - val_loss: 0.1231\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1138 - val_loss: 0.1246\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1147 - val_loss: 0.1233\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1159 - val_loss: 0.1230\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1134 - val_loss: 0.1232\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1129 - val_loss: 0.1232\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1146 - val_loss: 0.1222\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1159 - val_loss: 0.1553\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1149 - val_loss: 0.1219\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1133 - val_loss: 0.1274\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1143 - val_loss: 0.1295\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1129 - val_loss: 0.1217\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1132 - val_loss: 0.1214\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1132 - val_loss: 0.1242\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1122 - val_loss: 0.1263\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1132 - val_loss: 0.1206\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1125 - val_loss: 0.1208\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1120 - val_loss: 0.1231\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1127 - val_loss: 0.1204\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1116 - val_loss: 0.1216\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1115 - val_loss: 0.1227\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1122 - val_loss: 0.1220\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1124 - val_loss: 0.1205\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1118 - val_loss: 0.1205\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1122 - val_loss: 0.1228\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1120 - val_loss: 0.1210\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1150 - val_loss: 0.1210\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1134 - val_loss: 0.1215\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1141 - val_loss: 0.1236\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1117 - val_loss: 0.1207\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1113 - val_loss: 0.1210\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1112 - val_loss: 0.1212\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1126 - val_loss: 0.1224\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1120 - val_loss: 0.1218\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1141 - val_loss: 0.1200\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1117 - val_loss: 0.1197\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1129 - val_loss: 0.1215\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1129 - val_loss: 0.1217\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1135 - val_loss: 0.1219\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1128 - val_loss: 0.1217\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1128 - val_loss: 0.1251\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1139 - val_loss: 0.1228\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1126 - val_loss: 0.1218\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1135 - val_loss: 0.1219\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1155 - val_loss: 0.1241\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1128 - val_loss: 0.1220\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1133 - val_loss: 0.1221\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1125 - val_loss: 0.1223\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1127 - val_loss: 0.1219\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1135 - val_loss: 0.1232\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1136 - val_loss: 0.1221\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1122 - val_loss: 0.1283\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1139 - val_loss: 0.1214\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1132 - val_loss: 0.1212\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1125 - val_loss: 0.1231\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1115 - val_loss: 0.1236\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1126 - val_loss: 0.1231\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1114 - val_loss: 0.1221\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1115 - val_loss: 0.1219\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1113 - val_loss: 0.1249\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1116 - val_loss: 0.1210\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1106 - val_loss: 0.1210\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1105 - val_loss: 0.1248\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1109 - val_loss: 0.1215\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1113 - val_loss: 0.1211\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1119 - val_loss: 0.1218\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1111 - val_loss: 0.1228\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1101 - val_loss: 0.1206\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1105 - val_loss: 0.1209\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1131 - val_loss: 0.1229\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1109 - val_loss: 0.1215\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1107 - val_loss: 0.1202\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1096 - val_loss: 0.1208\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1098 - val_loss: 0.1222\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1102 - val_loss: 0.1204\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1109 - val_loss: 0.1212\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1105 - val_loss: 0.1207\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1095 - val_loss: 0.1251\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.1115 - val_loss: 0.1198\n"
     ]
    }
   ],
   "source": [
    "# Assuming x_train, y_train, x_test, y_test are already defined and properly preprocessed\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 100  # Number of epochs to train for\n",
    "batch_size = 64  # Batch size for training\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data_without_labels_2\n",
    "y_test = labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 12, 42)\n",
      "(2400, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1153\n",
      "Test Loss: 0.11531419306993484\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC & AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)  # Flatten the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reshaped = np.array(y_pred).reshape(-1, 1).flatten()\n",
    "true_labels_reshaped = np.array(y_test).reshape(-1, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800,)\n",
      "(28800,)\n"
     ]
    }
   ],
   "source": [
    "print(predictions_reshaped.shape)\n",
    "print(true_labels_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the ROC: 0.7089550547272967\n"
     ]
    }
   ],
   "source": [
    "auroc = roc_auc_score(true_labels_reshaped, predictions_reshaped)\n",
    "print(f\"Area Under the ROC: {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Precision-Recall Curve: 0.3003258879318601\n"
     ]
    }
   ],
   "source": [
    "auprc = average_precision_score(true_labels_reshaped, predictions_reshaped)\n",
    "print(f\"Area Under the Precision-Recall Curve: {auprc}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
